"""
template_analysis.py
────────────────────
Read two JSONL files produced by *template_siliconsampling.py* (or similar),
compute descriptive statistics, perform a Welch *t*-test, approximate the
Bayes Factor (BF₁₀) via a BIC method, and visualise the distributions.

Author: auto‑generated by ChatGPT (July 2025)
"""

from __future__ import annotations

import json
import math
import statistics
import csv
from collections import Counter
from pathlib import Path

import matplotlib.pyplot as plt
from matplotlib.ticker import MaxNLocator
from scipy.stats import t as _t_dist

# ──────────────────────────────────────────────────────────────
# Configuration
# ──────────────────────────────────────────────────────────────
FILE_A = Path("project-Silicon_Sampling/llm_outputs/output_memory_1.jsonl")       # Condition A
FILE_B = Path("project-Silicon_Sampling/llm_outputs/output_memory_2.jsonl")       # Condition B
SLOT_INDEX = 0                                           # which numeric slot to extract (0 = first number found)

KEY_NAME = "depth"                                       # numeric key in response_json dict
CONDITION_A_NAME = "Control"                             # human‑readable label for A
CONDITION_B_NAME = "Treatment"                           # human‑readable label for B
PLOT_TITLE = "Distributions of Depth Scores"
FIG_PATH = Path("project-Silicon_Sampling/llm_outputs/analysis_depth_distributions.png")

# Optional output: 
PRINT_RAW_VALUES = False                                            # Toggle to display the raw lists
CSV_PATH = Path("project-Silicon_Sampling/llm_outputs/data-silicon_sampling_values.csv")     # CSV output file
WRITE_CSV = False                                                   # toggle CSV export


# ──────────────────────────────────────────────────────────────
# Helper functions
# ──────────────────────────────────────────────────────────────
def _extract_json_payload(text: str) -> str:
    """
    Helper copied from functions_parallel_calls.py: isolate JSON part of *text*
    (handles ```json fences, curly quotes, leading noise, etc.).
    """
    import re

    text = text.strip()
    if text.startswith("```"):
        m = re.match(r"```(?:json)?\s*(.*?)\s*```", text, re.DOTALL)
        if m:
            text = m.group(1).strip()

    start, end = text.find("{"), text.rfind("}")
    if start != -1 and end != -1:
        text = text[start : end + 1]

    text = (
        text.replace("“", '"')
        .replace("”", '"')
        .replace("‘", "'")
        .replace("’", "'")
    )
    return text


def _safe_stdev(seq: list[float]) -> float:
    """Return statistics.stdev(seq) if len(seq) ≥ 2, else float('nan')."""
    return statistics.stdev(seq) if len(seq) >= 2 else float("nan")


def _read_slot_values(path: Path, slot_idx: int = 0, key_name: str | None = None) -> list[float]:
    """
    Return a list of numeric values extracted from *path*.

    Extraction rules (in priority order):
    1. If *key_name* is provided and `response_json` is a dict containing that
       key, use that numeric value.
    2. Else, if `response_json` is a dict, take the **first** numeric value.
    3. Else, if `response_json` is a list, take index *slot_idx* if numeric.
    4. Else, if `response_json` is a JSON‑serialised string, attempt to parse
       and then apply the rules above.
    """
    values: list[float] = []

    with path.open(encoding="utf-8") as fh:
        for line in fh:
            if not line.strip():
                continue  # skip blank lines
            try:
                rec = json.loads(line)
            except json.JSONDecodeError:
                continue  # malformed record – skip
            payload = rec.get("response_json")

            # If payload is a string, attempt to load JSON inside it
            if isinstance(payload, str):
                cleaned = _extract_json_payload(payload)
                try:
                    payload = json.loads(cleaned)
                except json.JSONDecodeError:
                    continue  # not valid JSON → skip

            # Case 1 & 2: dict
            if isinstance(payload, dict):
                if key_name and key_name in payload and isinstance(payload[key_name], (int, float)):
                    values.append(float(payload[key_name]))
                else:
                    for v in payload.values():
                        if isinstance(v, (int, float)):
                            values.append(float(v))
                            break

            # Case 3: list
            elif isinstance(payload, list):
                if len(payload) > slot_idx and isinstance(payload[slot_idx], (int, float)):
                    values.append(float(payload[slot_idx]))

    return values


def _welch_t(mean_a: float, mean_b: float, sd_a: float, sd_b: float, n_a: int, n_b: int):
    """Return t‑statistic, degrees of freedom, p‑value (two‑tailed)."""
    # Guard against insufficient sample size
    if n_a <= 1 or n_b <= 1:
        return float("nan"), float("nan"), float("nan")

    se = math.sqrt(sd_a**2 / n_a + sd_b**2 / n_b)
    t_stat = (mean_a - mean_b) / se

    num = (sd_a**2 / n_a + sd_b**2 / n_b) ** 2
    denom = ((sd_a**2 / n_a) ** 2) / (n_a - 1) + ((sd_b**2 / n_b) ** 2) / (n_b - 1)
    df = num / denom

    p_val = 2 * (1 - _t_dist.cdf(abs(t_stat), df))
    return t_stat, df, p_val


def _bic_bayes_factor(t_stat: float, df: float, n_total: int) -> float:
    """
    Approximate BF₁₀ from Welch t using Wagenmakers (2007) BIC method.
    ΔBIC = n * ln(1 + t²/df) ;  BF₁₀ = exp(ΔBIC / 2).
    """
    delta_bic = n_total * math.log1p(t_stat**2 / df)
    return math.exp(delta_bic / 2.0)


# ──────────────────────────────────────────────────────────────
# Data extraction
# ──────────────────────────────────────────────────────────────
vals_a = _read_slot_values(FILE_A, SLOT_INDEX, KEY_NAME)
vals_b = _read_slot_values(FILE_B, SLOT_INDEX, KEY_NAME)

if PRINT_RAW_VALUES:
    print("\n--- Raw numeric values ---")
    print(f"A ({FILE_A.name}): {vals_a}")
    print(f"B ({FILE_B.name}): {vals_b}")

if not vals_a or not vals_b:
    raise RuntimeError("No numeric values extracted – check JSONL structure.")

# Stats for A
n_a = len(vals_a)
mean_a = statistics.mean(vals_a)
sd_a = _safe_stdev(vals_a)
min_a, max_a, med_a = min(vals_a), max(vals_a), statistics.median(vals_a)

# Stats for B
n_b = len(vals_b)
mean_b = statistics.mean(vals_b)
sd_b = _safe_stdev(vals_b)
min_b, max_b, med_b = min(vals_b), max(vals_b), statistics.median(vals_b)

# Welch t‑test & Bayes Factor
t_stat, df, p_val = _welch_t(mean_a, mean_b, sd_a, sd_b, n_a, n_b)
bf10 = _bic_bayes_factor(t_stat, df, n_a + n_b)

# ──────────────────────────────────────────────────────────────
# Report
# ──────────────────────────────────────────────────────────────
def _fmt(x: float) -> str:
    return "nan" if math.isnan(x) else f"{x:.3f}"


print("\n=== Descriptive statistics ===")
print(f"{CONDITION_A_NAME} ({FILE_A.name}) – n={n_a}")
print(f"  Mean={_fmt(mean_a)}  SD={_fmt(sd_a)}  Median={_fmt(med_a)}  Min={_fmt(min_a)}  Max={_fmt(max_a)}")

print(f"{CONDITION_B_NAME} ({FILE_B.name}) – n={n_b}")
print(f"  Mean={_fmt(mean_b)}  SD={_fmt(sd_b)}  Median={_fmt(med_b)}  Min={_fmt(min_b)}  Max={_fmt(max_b)}")

print("\n=== Inferential statistics ===")
print(f"Welch t({df:.1f}) = {t_stat:.3f}")
print(f"Two‑tailed p-value = {p_val:.3e}")
print(f"Bayes Factor BF₁₀ ≈ {bf10:.3e}")

# ──────────────────────────────────────────────────────────────
# Visualisation
# ──────────────────────────────────────────────────────────────
# Create discrete histogram (bar chart) for each integer value in global range
global_min = int(min(min_a, min_b))
global_max = int(max(max_a, max_b))
x_vals = list(range(global_min, global_max + 1))

count_a = Counter(int(round(v)) for v in vals_a)
count_b = Counter(int(round(v)) for v in vals_b)

heights_a = [count_a.get(x, 0) for x in x_vals]
heights_b = [count_b.get(x, 0) for x in x_vals]

width = 0.4
offset = width / 2

fig, ax = plt.subplots()
ax.bar([x - offset for x in x_vals], heights_a, width=width, label=CONDITION_A_NAME)
ax.bar([x + offset for x in x_vals], heights_b, width=width, label=CONDITION_B_NAME)

ax.set_xlabel("Score (integer rounded)")
ax.set_ylabel("Frequency")
ax.set_title(PLOT_TITLE)
ax.legend()
ax.xaxis.set_major_locator(MaxNLocator(integer=True))

plt.tight_layout()
plt.savefig(FIG_PATH, dpi=300)
print(f"\nFigure saved to {FIG_PATH.resolve()}")

# ──────────────────────────────────────────────────────────────
# Optional CSV export of raw values
# ──────────────────────────────────────────────────────────────
if WRITE_CSV:
    max_len = max(len(vals_a), len(vals_b))
    pad_a = vals_a + [""] * (max_len - len(vals_a))
    pad_b = vals_b + [""] * (max_len - len(vals_b))

    with CSV_PATH.open("w", newline="", encoding="utf-8") as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow([CONDITION_A_NAME, CONDITION_B_NAME])
        writer.writerows(zip(pad_a, pad_b))

    print(f"CSV file saved to {CSV_PATH.resolve()}")
