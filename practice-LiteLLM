
# LiteLLM setup instructions: 
# https://docs.litellm.ai/docs/



from litellm import completion 
from dotenv import load_dotenv
import json 
import os 

import sys 




load_dotenv()  # Reads `.env` in project root, containing API keys 

os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY") # set in a separate ".env" file, ignored by github (.gitignore)
os.environ["GEMINI_API_KEY"] = os.getenv("GEMINI_API_KEY")
os.environ["OPENAI_PROJECT_ID"] = os.getenv("OPENAI_PROJECT_ID") 

messages = [{"role": "user", "content": "Ehi, come va?"}]

response = completion(
    model="openai/gpt-4o-mini",
    messages=messages
)
print(response)

print("Fine dell'output")
sys.exit(0)




# # ---------------------------------------------------------------------
# # Convert to JSON
# # ---------------------------------------------------------------------

# # Convert response to dictionary and print with formatting 
# response_dict = response.model_dump()
# print(json.dumps(response_dict, indent=2, ensure_ascii=False))



# # ---------------------------------------------------------------------
# # OLLAMA
# # ---------------------------------------------------------------------




# from ollama import chat 
# from ollama import ChatResponse

# response:
# #llama3.2

 









 











